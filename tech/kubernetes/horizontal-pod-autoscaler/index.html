<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>HorizontalPodAutoscaler | 太阳可以是蓝色</title>
<meta name=keywords content="kubernetes"><meta name=description content="在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。"><meta name=author content="iren."><link rel=canonical href=https://blog.mletter.cn/tech/kubernetes/horizontal-pod-autoscaler/><link crossorigin=anonymous href=/assets/css/stylesheet.54398d0fb317133a824d0a4034cf0879e64c7449a21217c62f4c262009100d8f.css integrity="sha256-VDmND7MXEzqCTQpANM8IeeZMdEmiEhfGL0wmIAkQDY8=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://blog.mletter.cn/tech/kubernetes/horizontal-pod-autoscaler/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=/view-image.min.js></script><script>window.ViewImage&&ViewImage.init("img")</script><style>:root{--sys-font-family:-apple-system, "PingFang SC", Georgia, 'Nimbus Roman No9 L', 'Hiragino Sans GB', 'Noto Serif SC', 'Microsoft Yahei', 'WenQuanYi Micro Hei', 'ST Heiti', sans-serif;--code-font-family:"JetBrains Mono", Menlo, Monaco, Consolas, "Courier New";--article-font-family:-apple-system, "PingFang SC", var(--base-font-family)}</style><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta property="og:url" content="https://blog.mletter.cn/tech/kubernetes/horizontal-pod-autoscaler/"><meta property="og:site_name" content="太阳可以是蓝色"><meta property="og:title" content="HorizontalPodAutoscaler"><meta property="og:description" content="在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-14T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-14T00:00:00+00:00"><meta property="article:tag" content="Kubernetes"><meta property="og:image" content="https://img14.360buyimg.com/ddimg/jfs/t1/164569/9/40677/14419/65bc6e4cFa1d8c0c3/5ccf7e6caadc9b83.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img14.360buyimg.com/ddimg/jfs/t1/164569/9/40677/14419/65bc6e4cFa1d8c0c3/5ccf7e6caadc9b83.jpg"><meta name=twitter:title content="HorizontalPodAutoscaler"><meta name=twitter:description content="在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"","item":"https://blog.mletter.cn/posts/"},{"@type":"ListItem","position":2,"name":"HorizontalPodAutoscaler","item":"https://blog.mletter.cn/tech/kubernetes/horizontal-pod-autoscaler/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"HorizontalPodAutoscaler","name":"HorizontalPodAutoscaler","description":"在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。","keywords":["kubernetes"],"articleBody":"HorizontalPodAutoscaler HPA官方文档 在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。\n水平扩缩意味着对增加的负载的响应是部署更多的 Pod。 这与垂直(Vertical)扩缩不同，对于 Kubernetes， 垂直扩缩意味着将更多资源（例如：内存或 CPU）分配给已经为工作负载运行的 Pod。\n如果负载减少，并且Pod的数量高于配置的最小值，HorizontalPodAutoscaler 会指示工作负载资源（Deployment、StatefulSet 或其他类似资源）缩减。\n水平Pod自动扩缩不适用于无法扩缩的对象: 例如DemonSet这种\n我们可以简单的通过 kubectl autoscale 命令来创建一个 HPA 资源对象，HPA Controller默认30s轮询一次（可通过 kube-controller-manager 的--horizontal-pod-autoscaler-sync-period 参数进行设置），查询指定的资源中的 Pod 资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。\nHorizontalPodAutoscaler 是如何工作的 Kubernetes 将水平 Pod 自动扩缩实现为一个间歇运行的控制回路（它不是一个连续的过程）。间隔由 kube-controller-manager 的 --horizontal-pod-autoscaler-sync-period 参数设置（默认间隔为 15 秒）。\n在每个时间段内，控制器管理器都会根据每个 HorizontalPodAutoscaler 定义中指定的指标查询资源利用率。 控制器管理器找到由 scaleTargetRef 定义的目标资源，然后根据目标资源的 .spec.selector 标签选择 Pod， 并从资源指标 API（针对每个 Pod 的资源指标）或自定义指标获取指标 API（适用于所有其他指标）\n对于按 Pod 统计的资源指标（如 CPU），控制器从资源指标 API 中获取每一个 HorizontalPodAutoscaler 指定的 Pod 的度量值，如果设置了目标使用率，控制器获取每个 Pod 中的容器资源使用情况， 并计算资源使用率。如果设置了 target 值，将直接使用原始数据（不再计算百分比）。 接下来，控制器根据平均的资源使用率或原始值计算出扩缩的比例，进而计算出目标副本数。 如果 Pod 使用自定义指示，控制器机制与资源指标类似，区别在于自定义指标只使用原始值，而不是使用率。 如果 Pod 使用对象指标和外部指标（每个指标描述一个对象信息）。 这个指标将直接根据目标设定值相比较，并生成一个上面提到的扩缩比例。 在 autoscaling/v2 版本 API 中，这个指标也可以根据 Pod 数量平分后再计算。 HorizontalPodAutoscaler的常见用途是将其配置为从聚合 API （metrics.k8s.io、custom.metrics.k8s.io 或 external.metrics.k8s.io）获取指标。 metrics.k8s.io API 通常由名为Metrics Server的插件提供，需要单独启动。有关资源指标的更多信息， 请参阅 Metrics Server。\nMetrics-Server 在 HPA 的第一个版本中，我们需要 Heapster 提供 CPU 和内存指标，在 HPA v2 过后就需要安装 Metrcis Server 了，Metrics Server 可以通过标准的 Kubernetes API 把监控数据暴露出来，有了 Metrics Server 之后，我们就完全可以通过标准的 Kubernetes API 来访问我们想要获取的监控数据了：\nhttps://api.k8s.io:8443/metrics.k8s.io/v1beta1/namespaces//pods/ 比如当我们访问上面的 API 的时候，我们就可以获取到该 Pod 的资源数据，这些数据其实是来自于 kubelet 的 Summary API 采集而来的。不过需要说明的是我们这里可以通过标准的 API 来获取资源监控数据，并不是因为 Metrics Server 就是 APIServer 的一部分，而是通过 Kubernetes 提供的 Aggregator 汇聚插件来实现的，是独立于 APIServer 之外运行的。\n聚合 API Aggregator 允许开发人员编写一个自己的服务，把这个服务注册到 Kubernetes 的 APIServer 里面去，这样我们就可以像原生的 APIServer 提供的 API 使用自己的 API 了，我们把自己的服务运行在 Kubernetes 集群里面，然后 Kubernetes 的 Aggregator 通过 Service 名称就可以转发到我们自己写的 Service 里面去了。这样这个聚合层就带来了很多好处：\n增加了 API 的扩展性，开发人员可以编写自己的 API 服务来暴露他们想要的 API。 丰富了 API，核心 kubernetes 团队阻止了很多新的 API 提案，通过允许开发人员将他们的 API 作为单独的服务公开，这样就无须社区繁杂的审查了。 开发分阶段实验性 API，新的 API 可以在单独的聚合服务中开发，当它稳定之后，在合并会 APIServer 就很容易了。 确保新 API 遵循 Kubernetes 约定，如果没有这里提出的机制，社区成员可能会被迫推出自己的东西，这样很可能造成社区成员和社区约定不一致。 部署HPA 我们要使用 HPA，就需要在集群中安装 Metrics Server 服务，要安装 Metrics Server 就需要开启 Aggregator，因为 Metrics Server 就是通过该代理进行扩展的，不过我们集群是通过 Kubeadm 搭建的，默认已经开启了，如果是二进制方式安装的集群，需要单独配置 kube-apsierver 添加如下所示的参数：\n--requestheader-client-ca-file= --requestheader-allowed-names=aggregator --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --proxy-client-cert-file= --proxy-client-key-file= Aggregator 聚合层启动完成后，就可以来安装 Metrics Server 了，我们可以获取该仓库的官方安装资源清单：\n官方仓库地址：https://github.com/kubernetes-sigs/metrics-server # 请修改镜像为: registry.aliyuncs.com/google_containers/metrics-server:v0.6.2 wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.6.2/components.yaml 如果出现x509: cannot validate certificate for 10.151.30.22 because it doesn’t contain any IP SANs这种错误,因为部署集群的时候，CA 证书并没有把各个节点的 IP 签上去，所以这里 Metrics Server 通过 IP 去请求时，提示签的证书没有对应的IP所导致的,我们可以添加一个--kubelet-insecure-tls参数跳过证书校验：\n- args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-preferred-address-types=InternalIP - --kubelet-use-node-status-port - --metric-resolution=15s - --kubelet-insecure-tls # 修改完成后记得部署 kubectl apply -f components.yaml 验证HPA是否安装成功,现在我们可以通过 kubectl top 命令来获取到资源数据了，证明 Metrics Server 已经安装成功了。\n[root@Online-Beijing-master1 ~]# kubectl top nodes NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% online-beijing-master1 82m 1% 1970Mi 12% online-beijing-master2 59m 0% 1379Mi 8% online-beijing-master3 61m 0% 1389Mi 8% online-beijing-node1 35m 0% 1957Mi 12% online-beijing-node2 33m 0% 1875Mi 11% online-beijing-node3 35m 0% 1045Mi 6% 首先我们先创建一个deployment，准备对他进行HPA\napiVersion: apps/v1 kind: Deployment metadata: name: hpa-demo-nginx namespace: default labels: k8s-app: hpa-demo-nginx spec: replicas: 1 selector: matchLabels: k8s-app: hpa-demo-nginx template: metadata: name: hpa-demo-nginx labels: k8s-app: hpa-demo-nginx spec: containers: - name: hpa-demo-nginx image: nginx:latest resources: requests: cpu: 10m memory: 100Mi securityContext: privileged: false 创建基于CPU的自动扩容 我们这次只针对CPU进行操作,后续我们会根据更多的自定义资源来进行扩缩容。\n现在我们来创建一个HPA，可以使用kubectl autoscale命令来创建：\nkubectl autoscale deployment hpa-demo-nginx --cpu-percent=10 --min=1 --max=6 此命令创建了一个关联资源hpa-demo-nginx 的HPA，最小的 pod 副本数为3，最大为6。HPA会根据设定的 cpu使用率（10%）动态的增加或者减少pod数量。\n[root@Online-Beijing-master1 ~]# kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE hpa-demo-nginx Deployment/hpa-demo-nginx /10% 1 6 0 8s 接下来对Pod进行压力测试,不断的去请求当前hpa-demo-nginxPod的IP\nkubectl run -i --tty load-generator --image=busybox /bin/sh while true; do wget -q -O- http://10.10.180.71; done 正常可以看到HPA已经正常工作了，Pod的副本数量已经分配到了我们当时指定的6个\n[root@Online-Beijing-master1 ~]# kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE hpa-demo-nginx Deployment/hpa-demo-nginx 78%/10% 1 6 6 4m20s 从kubernetesv1.12版本开始,我们可以通过设置kube-controller-manager的--horizontal-pod-autoscaler-downscale-stabilization参数来设置一个持续时间,指的是用于当前扩容操作完成后,多久以后才进行一次缩放操作。默认为5分钟,也就是五分钟后才会进行缩放。\n创建一个基于内存的自动扩容 跟CPU是一样的,都是基于metrics-server获取指标然后进行扩容。\napiVersion: apps/v1 kind: Deployment metadata: name: hpa-mem-demo namespace: default labels: k8s-app: hpa-mem-demo spec: replicas: 1 selector: matchLabels: k8s-app: hpa-mem-demo template: metadata: name: hpa-mem-demo labels: k8s-app: hpa-mem-demo spec: containers: - name: hpa-mem-demo image: nginx:latest resources: requests: memory: 20Mi cpu: 10m securityContext: privileged: true volumeMounts: - name: mount-configmap mountPath: /etc/script volumes: - name: mount-configmap configMap: name: increase-mem-config 这里和前面普通的应用有一些区别，我们将一个名为 increase-mem-config 的 ConfigMap 资源对象挂载到了容器中，该配置文件是用于后面增加容器内存占用的脚本，配置文件如下所示：（increase-mem-cm.yaml）\napiVersion: v1 kind: ConfigMap metadata: name: increase-mem-config data: increase-mem.sh: | #!/bin/bash mkdir /tmp/memory mount -t tmpfs -o size=40M tmpfs /tmp/memory dd if=/dev/zero of=/tmp/memory/block sleep 60 rm /tmp/memory/block umount /tmp/memory rmdir /tmp/memory 由于这里增加内存的脚本需要使用到 mount 命令，这需要声明为特权模式，所以我们添加了 securityContext.privileged=true 这个配置。现在我们直接创建上面的资源对象即可\nkubectl apply -f hpa-demo-mem.yaml kubectl apply -f increase-mem-config.yaml ","wordCount":"555","inLanguage":"zh","image":"https://img14.360buyimg.com/ddimg/jfs/t1/164569/9/40677/14419/65bc6e4cFa1d8c0c3/5ccf7e6caadc9b83.jpg","datePublished":"2023-02-14T00:00:00Z","dateModified":"2023-02-14T00:00:00Z","author":{"@type":"Person","name":"iren."},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.mletter.cn/tech/kubernetes/horizontal-pod-autoscaler/"},"publisher":{"@type":"Organization","name":"太阳可以是蓝色","logo":{"@type":"ImageObject","url":"https://blog.mletter.cn/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.mletter.cn/ accesskey=h title="太阳可以是蓝色 (Alt + H)">太阳可以是蓝色</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.mletter.cn/ title=主页><span>主页</span></a></li><li><a href=https://blog.mletter.cn/posts/ title=文章><span>文章</span></a></li><li><a href=https://blog.mletter.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://blog.mletter.cn/friends/ title=友联><span>友联</span></a></li><li><a href=https://blog.mletter.cn/about title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.mletter.cn/>主页</a>&nbsp;»&nbsp;<a href=https://blog.mletter.cn/posts/></a></div><h1 class="post-title entry-hint-parent">HorizontalPodAutoscaler</h1><div class=post-description>在Kubernetes 中HorizontalPodAutoscaler自动更新工作负载资源 （例如 Deployment 或者 StatefulSet）， 目的是自动扩缩工作负载以满足需求。</div><div class=post-meta><span title='2023-02-14 00:00:00 +0000 UTC'>二月 14, 2023</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;iren.&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/HorizontalPodAutoscaler.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#horizontalpodautoscaler>HorizontalPodAutoscaler</a><ul><li><a href=#horizontalpodautoscaler-是如何工作的>HorizontalPodAutoscaler 是如何工作的</a></li><li><a href=#metrics-server>Metrics-Server</a></li><li><a href=#聚合-api>聚合 API</a></li><li><a href=#部署hpa>部署HPA</a></li><li><a href=#创建基于cpu的自动扩容>创建基于CPU的自动扩容</a></li><li><a href=#创建一个基于内存的自动扩容>创建一个基于内存的自动扩容</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=horizontalpodautoscaler>HorizontalPodAutoscaler<a hidden class=anchor aria-hidden=true href=#horizontalpodautoscaler>#</a></h2><ul><li><a class=link href=https://kubernetes.io/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/ target=_blank rel=noopener>HPA官方文档</a></li></ul><p>在Kubernetes 中<code>HorizontalPodAutoscaler</code>自动更新工作负载资源 （例如 <a class=link href=https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank rel=noopener>Deployment</a> 或者 <a class=link href=https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/statefulset/ target=_blank rel=noopener>StatefulSet</a>）， 目的是自动扩缩工作负载以满足需求。</p><p>水平扩缩意味着对增加的负载的响应是部署更多的 <a class=link href=https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/ target=_blank rel=noopener>Pod</a>。 这与垂直(Vertical)扩缩不同，对于 Kubernetes， 垂直扩缩意味着将更多资源（例如：内存或 CPU）分配给已经为工作负载运行的 Pod。</p><p>如果负载减少，并且Pod的数量高于配置的最小值，<code>HorizontalPodAutoscaler</code> 会指示工作负载资源（Deployment、StatefulSet 或其他类似资源）缩减。</p><blockquote><p>水平Pod自动扩缩不适用于无法扩缩的对象: 例如DemonSet这种</p></blockquote><p>我们可以简单的通过 <code>kubectl autoscale</code> 命令来创建一个 HPA 资源对象，<code>HPA Controller</code>默认<code>30s</code>轮询一次（可通过 <code>kube-controller-manager</code> 的<code>--horizontal-pod-autoscaler-sync-period</code> 参数进行设置），查询指定的资源中的 Pod 资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。</p><h3 id=horizontalpodautoscaler-是如何工作的>HorizontalPodAutoscaler 是如何工作的<a hidden class=anchor aria-hidden=true href=#horizontalpodautoscaler-是如何工作的>#</a></h3><p><img style=max-width:100%;height:auto loading=lazy alt=工作图 loading=lazy src=https://bj.bcebos.com/baidu-rmb-video-cover-1/2f7f46bc72825e43f55f683e9ebefdd3.png></p><p>Kubernetes 将水平 Pod 自动扩缩实现为一个间歇运行的控制回路（它不是一个连续的过程）。间隔由 <a class=link href=https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/ target=_blank rel=noopener><code>kube-controller-manager</code></a> 的 <code>--horizontal-pod-autoscaler-sync-period</code> 参数设置（默认间隔为 15 秒）。</p><p>在每个时间段内，控制器管理器都会根据每个 HorizontalPodAutoscaler 定义中指定的指标查询资源利用率。 控制器管理器找到由 <code>scaleTargetRef</code> 定义的目标资源，然后根据目标资源的 <code>.spec.selector</code> 标签选择 Pod， 并从资源指标 API（针对每个 Pod 的资源指标）或自定义指标获取指标 API（适用于所有其他指标）</p><ul><li>对于按 Pod 统计的资源指标（如 CPU），控制器从资源指标 API 中获取每一个 HorizontalPodAutoscaler 指定的 Pod 的度量值，如果设置了目标使用率，控制器获取每个 Pod 中的容器<a class=link href=https://kubernetes.io/zh-cn/docs/concepts/configuration/manage-resources-containers/#requests-and-limits target=_blank rel=noopener>资源使用</a>情况， 并计算资源使用率。如果设置了 target 值，将直接使用原始数据（不再计算百分比）。 接下来，控制器根据平均的资源使用率或原始值计算出扩缩的比例，进而计算出目标副本数。</li><li>如果 Pod 使用自定义指示，控制器机制与资源指标类似，区别在于自定义指标只使用原始值，而不是使用率。</li><li>如果 Pod 使用对象指标和外部指标（每个指标描述一个对象信息）。 这个指标将直接根据目标设定值相比较，并生成一个上面提到的扩缩比例。 在 <code>autoscaling/v2</code> 版本 API 中，这个指标也可以根据 Pod 数量平分后再计算。</li></ul><p><code>HorizontalPodAutoscaler</code>的常见用途是将其配置为从<a class=link href=https://kubernetes.io/zh-cn/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/ target=_blank rel=noopener>聚合 API</a> （<code>metrics.k8s.io</code>、<code>custom.metrics.k8s.io</code> 或 <code>external.metrics.k8s.io</code>）获取指标。 <code>metrics.k8s.io</code> API 通常由名为<code>Metrics Server</code>的插件提供，需要单独启动。有关资源指标的更多信息， 请参阅 <a class=link href=https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server target=_blank rel=noopener>Metrics Server</a>。</p><h3 id=metrics-server>Metrics-Server<a hidden class=anchor aria-hidden=true href=#metrics-server>#</a></h3><p>在 HPA 的第一个版本中，我们需要 <code>Heapster</code> 提供 CPU 和内存指标，在 HPA v2 过后就需要安装 Metrcis Server 了，<code>Metrics Server</code> 可以通过标准的 Kubernetes API 把监控数据暴露出来，有了 <code>Metrics Server</code> 之后，我们就完全可以通过标准的 Kubernetes API 来访问我们想要获取的监控数据了：</p><pre tabindex=0><code class=language-bahs data-lang=bahs>https://api.k8s.io:8443/metrics.k8s.io/v1beta1/namespaces/&lt;namespace-name&gt;/pods/&lt;pod-name&gt;
</code></pre><p>比如当我们访问上面的 API 的时候，我们就可以获取到该 Pod 的资源数据，这些数据其实是来自于 kubelet 的 <code>Summary API</code> 采集而来的。不过需要说明的是我们这里可以通过标准的 API 来获取资源监控数据，并不是因为 <code>Metrics Server</code> 就是 APIServer 的一部分，而是通过 Kubernetes 提供的 <code>Aggregator</code> 汇聚插件来实现的，是独立于 APIServer 之外运行的。</p><h3 id=聚合-api>聚合 API<a hidden class=anchor aria-hidden=true href=#聚合-api>#</a></h3><p><code>Aggregator</code> 允许开发人员编写一个自己的服务，把这个服务注册到 Kubernetes 的 APIServer 里面去，这样我们就可以像原生的 APIServer 提供的 API 使用自己的 API 了，我们把自己的服务运行在 Kubernetes 集群里面，然后 Kubernetes 的 <code>Aggregator</code> 通过 Service 名称就可以转发到我们自己写的 Service 里面去了。这样这个聚合层就带来了很多好处：</p><ul><li>增加了 API 的扩展性，开发人员可以编写自己的 API 服务来暴露他们想要的 API。</li><li>丰富了 API，核心 kubernetes 团队阻止了很多新的 API 提案，通过允许开发人员将他们的 API 作为单独的服务公开，这样就无须社区繁杂的审查了。</li><li>开发分阶段实验性 API，新的 API 可以在单独的聚合服务中开发，当它稳定之后，在合并会 APIServer 就很容易了。</li><li>确保新 API 遵循 Kubernetes 约定，如果没有这里提出的机制，社区成员可能会被迫推出自己的东西，这样很可能造成社区成员和社区约定不一致。</li></ul><h3 id=部署hpa>部署HPA<a hidden class=anchor aria-hidden=true href=#部署hpa>#</a></h3><p>我们要使用 HPA，就需要在集群中安装 <code>Metrics Server</code> 服务，要安装 <code>Metrics Server</code> 就需要开启 <code>Aggregator</code>，因为 <code>Metrics Server</code> 就是通过该代理进行扩展的，不过我们集群是通过 Kubeadm 搭建的，默认已经开启了，如果是二进制方式安装的集群，需要单独配置 kube-apsierver 添加如下所示的参数：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>--<span class=l>requestheader-client-ca-file=&lt;path to aggregator CA cert&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>requestheader-allowed-names=aggregator</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>requestheader-extra-headers-prefix=X-Remote-Extra-</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>requestheader-group-headers=X-Remote-Group</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>requestheader-username-headers=X-Remote-User</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>proxy-client-cert-file=&lt;path to aggregator proxy cert&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>--<span class=l>proxy-client-key-file=&lt;path to aggregator proxy key&gt;</span><span class=w>
</span></span></span></code></pre></div><p><code>Aggregator</code> 聚合层启动完成后，就可以来安装 <code>Metrics Server</code> 了，我们可以获取该仓库的官方安装资源清单：</p><ul><li>官方仓库地址：https://github.com/kubernetes-sigs/metrics-server</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 请修改镜像为: registry.aliyuncs.com/google_containers/metrics-server:v0.6.2</span>
</span></span><span class=line><span class=cl>wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.6.2/components.yaml
</span></span></code></pre></div><p>如果出现<code>x509: cannot validate certificate for 10.151.30.22 because it doesn’t contain any IP SANs</code>这种错误,因为部署集群的时候，CA 证书并没有把各个节点的 IP 签上去，所以这里 <code>Metrics Server</code> 通过 IP 去请求时，提示签的证书没有对应的IP所导致的,我们可以添加一个<code>--kubelet-insecure-tls</code>参数跳过证书校验：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>- <span class=nt>args</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>cert-dir=/tmp</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>secure-port=4443</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>kubelet-preferred-address-types=InternalIP</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>kubelet-use-node-status-port</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>metric-resolution=15s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- --<span class=l>kubelet-insecure-tls</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># 修改完成后记得部署</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>kubectl apply -f components.yaml</span><span class=w>
</span></span></span></code></pre></div><p>验证HPA是否安装成功,现在我们可以通过 <code>kubectl top</code> 命令来获取到资源数据了，证明 <code>Metrics Server</code> 已经安装成功了。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>root@Online-Beijing-master1 ~<span class=o>]</span><span class=c1># kubectl top nodes</span>
</span></span><span class=line><span class=cl>NAME                     CPU<span class=o>(</span>cores<span class=o>)</span>   CPU%   MEMORY<span class=o>(</span>bytes<span class=o>)</span>   MEMORY%   
</span></span><span class=line><span class=cl>online-beijing-master1   82m          1%     1970Mi          12%       
</span></span><span class=line><span class=cl>online-beijing-master2   59m          0%     1379Mi          8%        
</span></span><span class=line><span class=cl>online-beijing-master3   61m          0%     1389Mi          8%        
</span></span><span class=line><span class=cl>online-beijing-node1     35m          0%     1957Mi          12%       
</span></span><span class=line><span class=cl>online-beijing-node2     33m          0%     1875Mi          11%       
</span></span><span class=line><span class=cl>online-beijing-node3     35m          0%     1045Mi          6% 
</span></span></code></pre></div><p>首先我们先创建一个<code>deployment</code>，准备对他进行HPA</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>default</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-demo-nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nginx:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>10m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>100Mi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>privileged</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span></code></pre></div><h3 id=创建基于cpu的自动扩容>创建基于CPU的自动扩容<a hidden class=anchor aria-hidden=true href=#创建基于cpu的自动扩容>#</a></h3><blockquote><p>我们这次只针对CPU进行操作,后续我们会根据更多的自定义资源来进行扩缩容。</p></blockquote><p>现在我们来创建一个<code>HPA</code>，可以使用<code>kubectl autoscale</code>命令来创建：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl autoscale deployment hpa-demo-nginx --cpu-percent<span class=o>=</span><span class=m>10</span> --min<span class=o>=</span><span class=m>1</span> --max<span class=o>=</span><span class=m>6</span>
</span></span></code></pre></div><p>此命令创建了一个关联资源<code>hpa-demo-nginx</code> 的<code>HPA</code>，最小的 pod 副本数为3，最大为6。<code>HPA</code>会根据设定的 cpu使用率（10%）动态的增加或者减少pod数量。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>root@Online-Beijing-master1 ~<span class=o>]</span><span class=c1># kubectl get hpa</span>
</span></span><span class=line><span class=cl>NAME               REFERENCE                     TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
</span></span><span class=line><span class=cl>hpa-demo-nginx   Deployment/hpa-demo-nginx   &lt;unknown&gt;/10%   <span class=m>1</span>         <span class=m>6</span>         <span class=m>0</span>          8s
</span></span></code></pre></div><p>接下来对Pod进行压力测试,不断的去请求当前<code>hpa-demo-nginx</code>Pod的IP</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl run -i --tty load-generator --image<span class=o>=</span>busybox /bin/sh
</span></span><span class=line><span class=cl><span class=k>while</span> true<span class=p>;</span> <span class=k>do</span> wget -q -O- http://10.10.180.71<span class=p>;</span> <span class=k>done</span>
</span></span></code></pre></div><p>正常可以看到<code>HPA</code>已经正常工作了，Pod的副本数量已经分配到了我们当时指定的6个</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=o>[</span>root@Online-Beijing-master1 ~<span class=o>]</span><span class=c1># kubectl get hpa</span>
</span></span><span class=line><span class=cl>NAME             REFERENCE                   TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
</span></span><span class=line><span class=cl>hpa-demo-nginx   Deployment/hpa-demo-nginx   78%/10%   <span class=m>1</span>         <span class=m>6</span>         <span class=m>6</span>          4m20s
</span></span></code></pre></div><p>从kubernetes<code>v1.12</code>版本开始,我们可以通过设置<code>kube-controller-manager</code>的<code>--horizontal-pod-autoscaler-downscale-stabilization</code>参数来设置一个持续时间,指的是用于当前扩容操作完成后,多久以后才进行一次缩放操作。默认为5分钟,也就是五分钟后才会进行缩放。</p><h3 id=创建一个基于内存的自动扩容>创建一个基于内存的自动扩容<a hidden class=anchor aria-hidden=true href=#创建一个基于内存的自动扩容>#</a></h3><p>跟CPU是一样的,都是基于<code>metrics-server</code>获取指标然后进行扩容。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>default</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>hpa-mem-demo</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nginx:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>20Mi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>10m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>privileged</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mount-configmap</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/etc/script</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mount-configmap</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>configMap</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>increase-mem-config</span><span class=w>
</span></span></span></code></pre></div><p>这里和前面普通的应用有一些区别，我们将一个名为 <code>increase-mem-config</code> 的 ConfigMap 资源对象挂载到了容器中，该配置文件是用于后面增加容器内存占用的脚本，配置文件如下所示：（increase-mem-cm.yaml）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ConfigMap</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>increase-mem-config</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>increase-mem.sh</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    #!/bin/bash  
</span></span></span><span class=line><span class=cl><span class=sd>    mkdir /tmp/memory  
</span></span></span><span class=line><span class=cl><span class=sd>    mount -t tmpfs -o size=40M tmpfs /tmp/memory  
</span></span></span><span class=line><span class=cl><span class=sd>    dd if=/dev/zero of=/tmp/memory/block  
</span></span></span><span class=line><span class=cl><span class=sd>    sleep 60 
</span></span></span><span class=line><span class=cl><span class=sd>    rm /tmp/memory/block  
</span></span></span><span class=line><span class=cl><span class=sd>    umount /tmp/memory  
</span></span></span><span class=line><span class=cl><span class=sd>    rmdir /tmp/memory</span><span class=w>    
</span></span></span></code></pre></div><p>由于这里增加内存的脚本需要使用到 <code>mount</code> 命令，这需要声明为特权模式，所以我们添加了 <code>securityContext.privileged=true</code> 这个配置。现在我们直接创建上面的资源对象即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f hpa-demo-mem.yaml
</span></span><span class=line><span class=cl>kubectl apply -f increase-mem-config.yaml 
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.mletter.cn/tags/kubernetes/>Kubernetes</a></li></ul><nav class=paginav><a class=prev href=https://blog.mletter.cn/tech/kubernetes/configmap-or-service/><span class=title>« 上一页</span><br><span>ConfigMap和Secret的使用</span>
</a><a class=next href=https://blog.mletter.cn/tech/kubernetes/apiserver-read/><span class=title>下一页 »</span><br><span>Kubernetes中Api-Server简单解读</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on x" href="https://x.com/intent/tweet/?text=HorizontalPodAutoscaler&amp;url=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f&amp;hashtags=kubernetes"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f&amp;title=HorizontalPodAutoscaler&amp;summary=HorizontalPodAutoscaler&amp;source=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f&title=HorizontalPodAutoscaler"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on whatsapp" href="https://api.whatsapp.com/send?text=HorizontalPodAutoscaler%20-%20https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on telegram" href="https://telegram.me/share/url?text=HorizontalPodAutoscaler&amp;url=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share HorizontalPodAutoscaler on ycombinator" href="https://news.ycombinator.com/submitlink?t=HorizontalPodAutoscaler&u=https%3a%2f%2fblog.mletter.cn%2ftech%2fkubernetes%2fhorizontal-pod-autoscaler%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div id=tcomment></div><script src=https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/twikoo/1.4.18/twikoo.all.min.js></script><script>twikoo.init({envId:"https://twikoo.mletter.cn/",el:"#tcomment"})</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.mletter.cn/>太阳可以是蓝色</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><br><span id=span style=color:#101011></span>
<script type=text/javascript>function runtime(){const a=new Date("12/07/2020 12:50:18"),r=new Date,c=r.getTime()-a.getTime(),l=24*60*60*1e3,e=c/l,t=Math.floor(e),n=(e-t)*24,s=Math.floor(n),o=(n-s)*60,i=Math.floor(o),d=Math.floor((o-i)*60);document.getElementById("span").innerHTML="已运行: "+t+"天"+s+"小时"+i+"分"+d+"秒"}runtime(),setInterval(runtime,1e3)</script><br><font color=#101011>本站由 <a href=https://www.netlify.com/ rel="noopener noreferrer nofollow" target=_blank>Netlify</a> 提供计算服务, 由 <a href=https://www.netlify.com/ rel="noopener noreferrer nofollow" target=_blank>Netlify</a> 提供全站加速服务。</font><br></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>const menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();const t=this.getAttribute("href").substr(1),n=document.querySelector(`[id='${decodeURIComponent(t)}']`);window.matchMedia("(prefers-reduced-motion: reduce)").matches?n.scrollIntoView():n.scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>const mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.classList.contains("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>